{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding relevant cases based on user query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_graph = tf.Graph()\n",
    "test_session = tf.Session(graph=test_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def cleanhtml(raw_html):\n",
    "    #raw_html.decode('unicode_escape').encode('ascii','ignore')\n",
    "    cleanr = re.compile('<.*?>|[\\W\\d]|_')\n",
    "    cleantext = re.sub(cleanr, ' ', raw_html)\n",
    "    cleantext = cleantext.lower()\n",
    "    return cleantext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing user input for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['harassed', 'by', 'husband', 'and', 'family', 'for', 'money', 'jewellery', 'dowry', 'beaten', 'by', 'husband', 'and', 'in', 'laws', 'threatened', 'to', 'kill', 'thrown', 'out', 'of', 'house', 'if', 'dowry', 'is', 'not', 'given', 'tried', 'to', 'poison', 'and', 'commit', 'suicide', 'i', 'suffer', 'from', 'depression', 'because', 'excessive', 'dowry', 'demands']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "input_file = open('input.txt', 'r', encoding='utf-8')\n",
    "para = input_file.read()\n",
    "y = cleanhtml(para)\n",
    "tokens = nltk.word_tokenize(y)\n",
    "n_documents = 11555\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specifying inputs to TensorFlow Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "window_size = 5\n",
    "vocabulary_size = 50000\n",
    "n_neg_samples = 64\n",
    "learning_rate = 1\n",
    "n_steps = 100000\n",
    "epochs = 3\n",
    "#Length of word vector\n",
    "embedding_size_w = 500\n",
    "#Length of document vector\n",
    "embedding_size_d = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with test_graph.as_default():\n",
    "    train_dataset = tf.placeholder(tf.int32, shape=[batch_size, window_size + 1])\n",
    "    train_labels = tf.placeholder(tf.int32, shape=[batch_size, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with test_graph.as_default():\n",
    "    word_embeddings = tf.Variable(\n",
    "        tf.random_uniform([vocabulary_size, embedding_size_w], -1.0, 1.0), name='word_embeddings')\n",
    "    doc_embeddings = tf.Variable(\n",
    "        tf.random_uniform([n_documents, embedding_size_w], -1.0, 1.0), name='doc_embeddings')\n",
    "    doc_embedding = tf.Variable(\n",
    "        tf.random_uniform([1, embedding_size_d], -1.0, 1.0), name='doc_embedding')\n",
    "\n",
    "    combined_vector_length = embedding_size_d + window_size * embedding_size_w\n",
    "\n",
    "    # Softmax weights\n",
    "    weights = tf.Variable(\n",
    "        tf.truncated_normal([vocabulary_size, combined_vector_length],\n",
    "                            stddev=1.0 / math.sqrt(combined_vector_length)), name='weights')\n",
    "    # Softmax biases\n",
    "    biases = tf.Variable(tf.zeros([vocabulary_size]), name='biases')\n",
    "    \n",
    "    # Concatenating doc vector and word vectors\n",
    "    combined_vector_length = embedding_size_d + window_size * embedding_size_w\n",
    "\n",
    "    input_matrix = []\n",
    "    for j in range(window_size):\n",
    "        # Find word embeddings for 'batch_size' number of words at window index j\n",
    "        input_word_embeddings = tf.nn.embedding_lookup(word_embeddings, train_dataset[:, j])\n",
    "        input_matrix.append(input_word_embeddings)\n",
    "\n",
    "    input_doc_embedding = tf.nn.embedding_lookup(doc_embedding, train_dataset[:, window_size])\n",
    "    input_matrix.append(input_doc_embedding)\n",
    "    input_matrix = tf.concat(1, input_matrix)\n",
    "\n",
    "    doc_loss = tf.nn.sampled_softmax_loss(weights, biases, input_matrix, \n",
    "                                      train_labels, n_neg_samples, vocabulary_size)\n",
    "\n",
    "    doc_optimizer = tf.train.AdagradOptimizer(learning_rate).minimize(doc_loss, var_list=[doc_embedding])\n",
    "\n",
    "    doc_init = tf.global_variables_initializer()\n",
    "\n",
    "    norm_d = tf.sqrt(tf.reduce_sum(tf.square(doc_embedding), 1, keep_dims=True))\n",
    "    normalized_doc_embedding = doc_embedding / norm_d\n",
    "    \n",
    "    saver = tf.train.Saver([word_embeddings, doc_embeddings, weights, biases])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with test_session.as_default():\n",
    "    doc_init.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restoring model from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "path = 'server-model'\n",
    "def save():\n",
    "    saver.save(sess, os.path.join(path, 'trained-model'))\n",
    "    with open(os.path.join(path, 'model_dict.json'), 'w', encoding='utf-8') as f:\n",
    "        json.dump(dictionary, f, ensure_ascii=False)\n",
    "    with open(os.path.join(path, 'model_rdict.json'), 'w', encoding='utf-8') as f:\n",
    "        json.dump(reverse_dictionary, f, ensure_ascii=False)\n",
    "        \n",
    "def restore(session):\n",
    "    with open(os.path.join(path, 'model_dict.json'), 'r', encoding='utf-8') as f:\n",
    "        dictionary = json.load(f)\n",
    "    with open(os.path.join(path, 'model_rdict.json'), 'r', encoding='utf-8') as f:\n",
    "        reverse_dictionary = json.load(f)\n",
    "    saver.restore(session, os.path.join(path, 'trained-model'))\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with test_graph.as_default():\n",
    "    dictionary = restore(test_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.17180037  -0.54881263  -0.39782715 ...,   1.80713189   2.05496287\n",
      "    1.47726083]\n",
      " [ -0.77837354   0.94513148 -10.13407326 ...,   2.66784477   2.93940616\n",
      "    4.32101774]\n",
      " [  1.43049073  -0.76193863  -3.26454353 ...,   3.75134826   4.48116827\n",
      "   -1.14625895]\n",
      " ..., \n",
      " [ -0.87669206   0.45652223  -0.919384   ...,   0.90272999  -0.25631523\n",
      "   -0.81226397]\n",
      " [  0.24927497   0.44542861  -0.1495347  ...,  -0.84609509  -0.4349165\n",
      "   -0.53321362]\n",
      " [  0.47091246  -0.28414917   0.81335592 ...,  -0.19377565   0.74336004\n",
      "    0.22409534]]\n"
     ]
    }
   ],
   "source": [
    "with test_session.as_default(), test_graph.as_default():\n",
    "    print(doc_embeddings.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain document vector for user provided paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6939, 9, 830, 5, 500, 11, 776, 9620, 1348, 7544, 9, 830, 5, 4, 600, 3797, 3, 3835, 4604, 77, 2, 294, 62, 1348, 8, 15, 149, 1382, 3, 4184, 5, 1885, 2111, 76, 1754, 30, 10567, 296, 3100, 1348, 2840]\n"
     ]
    }
   ],
   "source": [
    "doc_word_ids = []\n",
    "for word in tokens:\n",
    "    if word in dictionary:\n",
    "        index = dictionary[word]\n",
    "    else:\n",
    "        index = 0  # dictionary['UNK']\n",
    "    doc_word_ids.append(index)\n",
    "print(doc_word_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import compress\n",
    "data_index = 0\n",
    "batch = np.ndarray(shape=(batch_size, window_size + 1), dtype=np.int32)\n",
    "labels = np.ndarray(shape=(batch_size, 1), dtype=np.int32)\n",
    "span = window_size + 1\n",
    "buffer = collections.deque(maxlen=span) # used for collecting word_ids[data_index] in the sliding window\n",
    "def generate_batch_pvdm_doc(word_ids, batch_size, window_size):\n",
    "    '''\n",
    "    Batch generator for PV-DM (Distributed Memory Model of Paragraph Vectors).\n",
    "    batch should be a shape of (batch_size, window_size+1)\n",
    "    Parameters\n",
    "    ----------\n",
    "    doc_ids: list of document indices \n",
    "    word_ids: list of word indices\n",
    "    batch_size: number of words in each mini-batch\n",
    "    window_size: number of leading words before the target word \n",
    "    '''\n",
    "    global data_index\n",
    "    global batch\n",
    "    global labels\n",
    "    global span\n",
    "    global buffer\n",
    "    # collect the first window of words\n",
    "    if (data_index == 0):\n",
    "        for _ in range(span):\n",
    "            buffer.append(doc_word_ids[data_index])\n",
    "            data_index = (data_index + 1)\n",
    "    mask = [1] * span\n",
    "    mask[-1] = 0 \n",
    "    i = 0\n",
    "    doc_id = 0\n",
    "    while i < batch_size:\n",
    "        if (data_index == len(doc_word_ids)):\n",
    "            data_index = 0\n",
    "            return None, None\n",
    "        # all leading words and the doc_id\n",
    "        batch[i, :] = list(compress(buffer, mask)) + [doc_id]\n",
    "        labels[i, 0] = buffer[-1] # the last word at end of the sliding window\n",
    "        i += 1\n",
    "        # move the sliding window  \n",
    "        buffer.append(doc_word_ids[data_index])\n",
    "        data_index += 1            \n",
    "    return batch, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferring the input document vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at step 1: 1608.716553\n",
      "Average loss at step 2: 1227.205811\n",
      "Average loss at step 3: 804.639404\n",
      "Average loss at step 4: 2009.318726\n",
      "Average loss at step 5: 2072.885986\n",
      "Average loss at step 6: 1245.071533\n",
      "broke\n",
      "Average loss at step 7: 972.971497\n",
      "Average loss at step 8: 670.461060\n",
      "Average loss at step 9: 753.789673\n",
      "Average loss at step 10: 369.410156\n",
      "Average loss at step 11: 2188.986816\n",
      "Average loss at step 12: 1862.519775\n",
      "Average loss at step 13: 584.724304\n",
      "broke\n",
      "Average loss at step 14: 718.570190\n",
      "Average loss at step 15: 1036.047241\n",
      "Average loss at step 16: 835.010559\n",
      "Average loss at step 17: 292.137543\n",
      "Average loss at step 18: 1959.807861\n",
      "Average loss at step 19: 1774.422607\n",
      "Average loss at step 20: 312.335144\n",
      "broke\n",
      "Average loss at step 21: 447.456696\n",
      "Average loss at step 22: 695.523376\n",
      "Average loss at step 23: 829.688110\n",
      "Average loss at step 24: 362.546722\n",
      "Average loss at step 25: 1690.319702\n",
      "Average loss at step 26: 1676.359741\n",
      "Average loss at step 27: 524.598999\n",
      "broke\n",
      "Average loss at step 28: 404.833679\n",
      "Average loss at step 29: 1017.221069\n",
      "Average loss at step 30: 568.195801\n",
      "Average loss at step 31: 696.566711\n",
      "Average loss at step 32: 1816.763672\n",
      "Average loss at step 33: 1638.248291\n",
      "Average loss at step 34: 400.400513\n",
      "broke\n"
     ]
    }
   ],
   "source": [
    "average_loss = 0\n",
    "step = 0\n",
    "for epoch in range(5):\n",
    "    while(True):\n",
    "        batch_data, batch_labels = generate_batch_pvdm_doc(doc_word_ids,\n",
    "            batch_size, window_size)\n",
    "        if batch_data is None:\n",
    "            print('broke')\n",
    "            break\n",
    "        feed_dict = {train_dataset : batch_data, train_labels : batch_labels}\n",
    "        op, l = test_session.run([doc_optimizer, doc_loss], feed_dict=feed_dict)\n",
    "        loss = np.mean(l)\n",
    "        if step > 0:\n",
    "            average_loss = average_loss / 2000\n",
    "            # The average loss is an estimate of the loss over the last 2000 batches.\n",
    "            print('Average loss at step %d: %f' % (step, loss))\n",
    "            average_loss = 0\n",
    "        step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with test_session.as_default(), test_graph.as_default():\n",
    "    word_embeddings = word_embeddings.eval()\n",
    "    doc_embeddings = doc_embeddings.eval()\n",
    "    doc_embedding = doc_embedding.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -1.61235058e+00,  -1.98829699e+00,   3.81818116e-01,\n",
       "         -2.14010096e+00,   1.92247617e+00,  -9.25120711e-01,\n",
       "         -7.59949636e+00,   3.27577496e+00,   2.48243308e+00,\n",
       "          7.33018219e-01,   1.95946205e+00,   1.48673797e+00,\n",
       "          1.27801239e+00,   3.30408788e+00,   7.62083352e-01,\n",
       "         -3.53002250e-01,   8.19922745e-01,   3.97603154e+00,\n",
       "         -3.81781667e-01,  -5.04135418e+00,   5.94559073e-01,\n",
       "         -9.91142035e-01,   4.76521778e+00,   3.02548027e+00,\n",
       "         -2.15528488e+00,  -2.75961328e+00,  -2.07385087e+00,\n",
       "          2.38021874e+00,   5.56441069e-01,  -1.25326324e+00,\n",
       "         -7.40746856e-01,  -2.63129687e+00,   2.05743217e+00,\n",
       "         -3.51938844e+00,  -1.86649859e+00,  -2.19924021e+00,\n",
       "         -8.93701375e-01,  -1.61902761e+00,   2.06132218e-01,\n",
       "         -4.96853352e+00,   1.72255778e+00,   2.16816711e+00,\n",
       "          2.62566400e+00,  -6.53638542e-01,  -5.82914972e+00,\n",
       "         -4.76629162e+00,   2.09511232e+00,  -5.55043340e-01,\n",
       "         -3.74030471e+00,  -3.83063912e+00,   2.68863916e-01,\n",
       "          1.79640621e-01,   4.60632086e+00,  -2.45454693e+00,\n",
       "         -1.29513407e+00,   8.36036921e-01,   3.28159022e+00,\n",
       "         -1.82499361e+00,   2.59169269e+00,   4.23041284e-02,\n",
       "          4.43118185e-01,   2.37715006e+00,  -3.83293748e+00,\n",
       "          4.92902935e-01,   5.09046912e-01,   5.13767815e+00,\n",
       "         -1.03393984e+00,   3.49414515e+00,  -7.86829472e-01,\n",
       "         -1.63885546e+00,  -4.97099400e+00,  -5.79233217e+00,\n",
       "          1.07438731e+00,   1.84170663e+00,   3.62091541e+00,\n",
       "         -1.34985816e+00,   3.14675152e-01,   6.29937029e+00,\n",
       "          1.18676078e+00,  -2.87876391e+00,  -6.03379965e-01,\n",
       "          3.83268142e+00,  -4.32587683e-01,  -5.72596610e-01,\n",
       "          1.75521344e-01,   5.15538263e+00,   2.88355565e+00,\n",
       "         -8.32911074e-01,  -3.05723953e+00,   3.81846809e+00,\n",
       "          2.87335467e+00,  -2.14769268e+00,   2.69349718e+00,\n",
       "         -7.05140904e-02,   5.16432166e-01,  -1.40301132e+00,\n",
       "          5.05679369e+00,  -4.34426367e-01,   4.45830584e+00,\n",
       "          3.96094966e+00,  -2.33220056e-01,  -2.03115487e+00,\n",
       "         -1.82739568e+00,  -2.62745357e+00,  -2.23084140e+00,\n",
       "          6.78431869e-01,   1.56997955e+00,  -1.82791650e+00,\n",
       "         -5.50661516e+00,  -8.82315874e-01,   2.98838472e+00,\n",
       "          6.63045406e-01,   2.86406446e+00,   3.71014595e-01,\n",
       "         -7.07326794e+00,  -2.29475307e+00,  -2.22888231e+00,\n",
       "          2.09103560e+00,  -1.29714167e+00,   5.78574944e+00,\n",
       "         -3.31680870e+00,   2.57579136e+00,  -2.35159802e+00,\n",
       "         -7.77578592e-01,   4.58986378e+00,  -4.51784992e+00,\n",
       "         -1.94925392e+00,  -8.91345501e-01,  -1.71527708e+00,\n",
       "         -4.67664194e+00,  -5.24378419e-01,   3.82357049e+00,\n",
       "         -3.49724388e+00,  -1.68492770e+00,   2.14703608e+00,\n",
       "          6.08187318e-01,   5.27399778e-01,  -7.05123991e-02,\n",
       "         -1.56406856e+00,  -5.21022558e+00,  -1.65779614e+00,\n",
       "         -4.53082800e+00,  -4.76924086e+00,   8.03676307e-01,\n",
       "          1.22150135e+00,  -3.30985427e+00,   2.28430843e+00,\n",
       "          1.70058298e+00,  -1.08041859e+00,   1.08067870e+00,\n",
       "          4.46078682e+00,   5.12131977e+00,  -1.92955697e+00,\n",
       "         -4.07749224e+00,  -3.83831233e-01,   8.40961874e-01,\n",
       "         -5.08822381e-01,   2.60501170e+00,   2.48572016e+00,\n",
       "          2.37573743e+00,  -2.62328815e+00,  -5.57135880e-01,\n",
       "         -2.69108510e+00,   4.09290552e+00,   1.67469621e+00,\n",
       "          4.41988945e+00,  -1.86714315e+00,   7.57043481e-01,\n",
       "          4.60704714e-01,   2.03026843e+00,   8.58012795e-01,\n",
       "          4.90240145e+00,  -1.26185238e+00,   2.77012289e-01,\n",
       "         -2.56051755e+00,   1.77913889e-01,   4.21391582e+00,\n",
       "         -1.48909545e+00,   3.53547287e+00,  -5.77182412e-01,\n",
       "         -4.12076092e+00,  -1.15341055e+00,  -8.78020048e-01,\n",
       "         -5.60943413e+00,   3.66921037e-01,   4.49618626e+00,\n",
       "         -3.99895835e+00,  -3.00035501e+00,   1.52853656e+00,\n",
       "          1.88480878e+00,  -1.34276831e+00,  -4.49608237e-01,\n",
       "          2.07111740e+00,  -5.42869949e+00,  -2.28355408e+00,\n",
       "          1.68821311e+00,   2.75742918e-01,   2.68751478e+00,\n",
       "          4.25691652e+00,   1.12834430e+00,  -5.19542408e+00,\n",
       "         -2.48618841e-01,   5.81406713e-01,   2.10498071e+00,\n",
       "          1.15976799e+00,   3.51282215e+00,   3.41639924e+00,\n",
       "          1.01118076e+00,  -3.40537930e+00,  -2.29250264e+00,\n",
       "          2.04081988e+00,   1.73447207e-02,   9.92914796e-01,\n",
       "          1.70191145e+00,   6.85280561e-02,   2.99497938e+00,\n",
       "         -4.86535645e+00,   2.72297096e+00,   2.10005951e+00,\n",
       "          2.49176526e+00,  -3.01291180e+00,  -1.07340789e+00,\n",
       "         -8.17746937e-01,   1.96216166e+00,  -2.03251576e+00,\n",
       "          4.64145124e-01,   1.83033884e-01,   3.08820128e+00,\n",
       "          4.48481607e+00,   9.92922843e-01,   4.05989699e-02,\n",
       "         -4.60949612e+00,  -1.28863126e-01,  -1.33688211e+00,\n",
       "          2.72238088e+00,  -5.66616297e-01,   2.16577601e+00,\n",
       "         -3.14489961e+00,   4.78585690e-01,   2.20089841e+00,\n",
       "          2.48870921e+00,   4.46422338e-01,   3.09829855e+00,\n",
       "          5.59776211e+00,   1.85869348e+00,   2.26257777e+00,\n",
       "         -3.80763739e-01,   5.09203672e-01,  -1.76610425e-02,\n",
       "         -2.33272123e+00,   3.25252199e+00,   3.00821137e+00,\n",
       "         -1.80885160e+00,  -6.02602720e-01,  -5.09915924e+00,\n",
       "         -8.80386055e-01,  -5.31309724e-01,   1.06285417e+00,\n",
       "         -4.24192715e+00,  -6.67260838e+00,  -5.75310659e+00,\n",
       "         -1.51325440e+00,  -3.43708730e+00,   9.54414368e-01,\n",
       "         -1.62886882e+00,  -9.52281356e-01,  -5.44836903e+00,\n",
       "          1.70786417e+00,  -1.10023046e+00,  -5.66413498e+00,\n",
       "          4.01303148e+00,  -1.98776877e+00,  -8.58004689e-01,\n",
       "         -2.59941888e+00,  -6.74975336e-01,  -4.52886200e+00,\n",
       "         -4.87904644e+00,  -1.07411839e-01,   3.98070598e+00,\n",
       "          3.28146195e+00,   6.83388186e+00,  -1.52312970e+00,\n",
       "         -3.64228994e-01,   3.40879631e+00,  -1.54880738e+00,\n",
       "         -2.96503067e+00,  -1.61966419e+00,  -2.05202565e-01,\n",
       "          6.99731255e+00,  -8.11879539e+00,   3.69334072e-01,\n",
       "         -7.31742144e-01,   5.47343135e-01,   5.59318590e+00,\n",
       "          5.82792282e-01,   5.90295196e-01,   2.82193232e+00,\n",
       "         -4.21981621e+00,   1.08779776e+00,   3.16242528e+00,\n",
       "          2.64371634e+00,  -5.24062586e+00,  -2.64286900e+00,\n",
       "          3.25079608e+00,  -3.23479128e+00,   4.11855221e+00,\n",
       "         -4.59314299e+00,  -2.59037471e+00,  -5.16594291e-01,\n",
       "          1.87197781e+00,   7.60473609e-01,   1.43417621e+00,\n",
       "         -2.87535459e-01,  -2.04314280e+00,   5.28173566e-01,\n",
       "         -5.94911242e+00,  -3.31250608e-01,  -2.09465146e+00,\n",
       "         -8.60236824e-01,  -2.63872242e+00,  -4.42907780e-01,\n",
       "         -1.04826558e+00,  -4.86937612e-01,   1.56459010e+00,\n",
       "         -1.46797419e+00,   1.67926252e+00,   1.74067569e+00,\n",
       "         -6.15301418e+00,   1.49949670e+00,   4.03304434e+00,\n",
       "         -9.71236515e+00,   4.10430956e+00,  -6.11605549e+00,\n",
       "         -4.29874468e+00,  -1.12298512e+00,   2.17365742e+00,\n",
       "         -3.43259525e+00,   4.72441006e+00,  -1.75431967e+00,\n",
       "         -4.78736258e+00,   3.20808244e+00,   5.47626734e-01,\n",
       "         -3.42702642e-02,   2.73720860e+00,  -3.68318272e+00,\n",
       "         -9.99360442e-01,  -5.03157318e-01,  -2.03988504e+00,\n",
       "          4.68262720e+00,   1.52357829e+00,   6.71014643e+00,\n",
       "         -3.14096379e+00,  -4.83719301e+00,  -8.88341308e-01,\n",
       "          5.00800276e+00,  -4.51284027e+00,   1.19752288e+00,\n",
       "         -2.81741023e+00,   3.90346622e+00,   1.12831688e+00,\n",
       "          1.60632670e+00,  -9.31777239e-01,  -2.81740069e+00,\n",
       "         -7.77973413e-01,   4.73651838e+00,   3.31673551e+00,\n",
       "          4.21272707e+00,   2.28624046e-03,  -4.33204556e+00,\n",
       "         -1.22888732e+00,   3.06227595e-01,  -2.30906057e+00,\n",
       "          2.69534826e+00,  -1.32050872e+00,   1.00181615e+00,\n",
       "          1.82859194e+00,   3.64797497e+00,  -7.62351513e+00,\n",
       "         -2.02763653e+00,  -1.37581062e+00,  -1.30338049e+00,\n",
       "          3.31912088e+00,   3.56802702e+00,  -5.46221375e-01,\n",
       "         -3.08279014e+00,   7.52731919e-01,   1.38735211e+00,\n",
       "          8.96709251e+00,   3.24801826e+00,  -6.01024342e+00,\n",
       "         -3.13646770e+00,  -5.81563139e+00,  -5.39432669e+00,\n",
       "         -3.09676433e+00,   1.61582339e+00,  -4.82341409e-01,\n",
       "         -5.69497776e+00,   3.25075483e+00,   2.51960427e-01,\n",
       "          1.68386507e+00,  -1.13728189e+00,   7.17910337e+00,\n",
       "          3.04109979e+00,  -2.60935450e+00,   3.41194344e+00,\n",
       "         -4.47881413e+00,  -5.17588854e-01,   1.32392967e+00,\n",
       "         -4.66330409e-01,   1.40703285e+00,  -4.73493624e+00,\n",
       "          2.52613091e+00,   1.09492064e+00,   1.02852631e+00,\n",
       "          1.11360490e+00,   3.42465734e+00,   3.10386270e-01,\n",
       "         -1.97947776e+00,  -2.10127473e-01,   1.48560989e+00,\n",
       "          3.23148704e+00,  -1.74502039e+00,  -8.91485596e+00,\n",
       "         -2.67496854e-02,  -3.79149079e-01,   1.07689571e+00,\n",
       "         -3.56181383e+00,   4.26572227e+00,  -1.77631092e+00,\n",
       "          3.73914510e-01,   1.36216557e+00,   3.29641175e+00,\n",
       "         -2.97335005e+00,  -7.17177629e-01,  -4.32467747e+00,\n",
       "          2.07746100e+00,   1.83795249e+00,   1.06394947e+00,\n",
       "         -3.21354771e+00,   7.47126341e-03,   1.09874547e+00,\n",
       "          3.32775664e+00,   8.96465123e-01,  -2.26964664e+00,\n",
       "          1.08782649e+00,  -3.19022250e+00,  -2.80364466e+00,\n",
       "          7.33558118e-01,   2.31277323e+00,   1.78949559e+00,\n",
       "          3.78202438e+00,   3.19778681e+00,  -1.22394070e-01,\n",
       "          6.37831688e+00,   3.19440663e-01,   3.01143694e+00,\n",
       "          3.76527953e+00,   1.60237384e+00,   7.89149642e-01,\n",
       "         -3.85796309e+00,   5.21088123e-01,   3.59226775e+00,\n",
       "          1.54306817e+00,  -2.42997789e+00,   2.15585780e+00,\n",
       "          9.01623726e-01,   2.98608351e+00,  -8.53294611e-01,\n",
       "          4.08861780e+00,   5.90830445e-01,   1.48492539e+00,\n",
       "         -1.34817541e+00,   1.75694561e+00,   7.29746521e-02,\n",
       "         -1.86134171e+00,   1.61749351e+00,  -2.41971537e-01,\n",
       "          3.74768066e+00,   2.23052549e+00,   5.59336245e-01,\n",
       "          4.01835394e+00,  -3.99525642e+00,  -7.25239134e+00,\n",
       "         -3.39955926e+00,   3.19533443e+00,  -5.86382055e+00,\n",
       "          4.41651201e+00,   2.87073612e+00,   1.66712821e+00,\n",
       "         -1.30002689e+00,  -2.53853774e+00,   5.59575856e-01,\n",
       "         -1.42384887e+00,   3.36628532e+00,   1.74294126e+00,\n",
       "          6.89592302e-01,  -5.12221813e-01,   1.86359394e+00,\n",
       "         -3.81467509e+00,  -1.96812546e+00]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading cases from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'docs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-b2451407b97e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcases\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcase\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mn_documents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'docs' is not defined"
     ]
    }
   ],
   "source": [
    "import json\n",
    "tids = []\n",
    "case_file = open('all_cases.txt', 'r', encoding='utf-8')\n",
    "cases = json.load(case_file)\n",
    "i = 0\n",
    "for case in cases:\n",
    "    tids.append(case[0])\n",
    "n_documents = len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12564942\n",
      "649 : 12564942\n",
      "63 : 142324899\n",
      "420 : 149450971\n",
      "8950 : 488831\n",
      "8880 : 1926347\n",
      "795 : 107667489\n",
      "9075 : 72187374\n",
      "132 : 172153811\n",
      "6 : 40022871\n",
      "632 : 41002179\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import spatial\n",
    "with test_session.as_default():\n",
    "    cosines = []\n",
    "    for i in range(len(doc_embeddings)):\n",
    "        cosines.append(spatial.distance.cosine(doc_embedding, doc_embeddings[i]))\n",
    "    #ind = np.argpartition(cosines, 4)\n",
    "    cos = np.array(cosines)\n",
    "    ind = cos.argsort()[:10]\n",
    "    print(tids[ind[0]])\n",
    "    for i in ind:\n",
    "        print('{} : {}'.format(i, tids[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tids[184]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:condatensorflow]",
   "language": "python",
   "name": "conda-env-condatensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
